#!/usr/bin/env python3
"""
ç»Ÿä¸€æ–°é—»åˆ†æå·¥å…·
æ•´åˆAè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ç­‰ä¸åŒå¸‚åœºçš„æ–°é—»è·å–é€»è¾‘åˆ°ä¸€ä¸ªå·¥å…·å‡½æ•°ä¸­
è®©å¤§æ¨¡å‹åªéœ€è¦è°ƒç”¨ä¸€ä¸ªå·¥å…·å°±èƒ½è·å–æ‰€æœ‰ç±»å‹è‚¡ç¥¨çš„æ–°é—»æ•°æ®
"""

import logging
from datetime import datetime
import re

logger = logging.getLogger(__name__)

class UnifiedNewsAnalyzer:
    """ç»Ÿä¸€æ–°é—»åˆ†æå™¨ï¼Œæ•´åˆæ‰€æœ‰æ–°é—»è·å–é€»è¾‘"""
    
    def __init__(self, toolkit):
        """åˆå§‹åŒ–ç»Ÿä¸€æ–°é—»åˆ†æå™¨
        
        Args:
            toolkit: åŒ…å«å„ç§æ–°é—»è·å–å·¥å…·çš„å·¥å…·åŒ…
        """
        self.toolkit = toolkit
        
    def get_stock_news_unified(self, stock_code: str, max_news: int = 10, model_info: str = "") -> str:
        """
        ç»Ÿä¸€æ–°é—»è·å–æ¥å£
        æ ¹æ®è‚¡ç¥¨ä»£ç è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹å¹¶è·å–ç›¸åº”æ–°é—»
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            max_news: æœ€å¤§æ–°é—»æ•°é‡
            model_info: å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯ï¼Œç”¨äºç‰¹æ®Šå¤„ç†
            
        Returns:
            str: æ ¼å¼åŒ–çš„æ–°é—»å†…å®¹
        """
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å¼€å§‹è·å– {stock_code} çš„æ–°é—»ï¼Œæ¨¡å‹: {model_info}")
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ¤– å½“å‰æ¨¡å‹ä¿¡æ¯: {model_info}")
        
        # è¯†åˆ«è‚¡ç¥¨ç±»å‹
        stock_type = self._identify_stock_type(stock_code)
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] è‚¡ç¥¨ç±»å‹: {stock_type}")
        
        # æ ¹æ®è‚¡ç¥¨ç±»å‹è°ƒç”¨ç›¸åº”çš„è·å–æ–¹æ³•
        if stock_type == "Aè‚¡":
            result = self._get_a_share_news(stock_code, max_news, model_info)
        elif stock_type == "æ¸¯è‚¡":
            result = self._get_hk_share_news(stock_code, max_news, model_info)
        elif stock_type == "ç¾è‚¡":
            result = self._get_us_share_news(stock_code, max_news, model_info)
        else:
            # é»˜è®¤ä½¿ç”¨Aè‚¡é€»è¾‘
            result = self._get_a_share_news(stock_code, max_news, model_info)
        
        # ğŸ” æ·»åŠ è¯¦ç»†çš„ç»“æœè°ƒè¯•æ—¥å¿—
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“Š æ–°é—»è·å–å®Œæˆï¼Œç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“‹ è¿”å›ç»“æœé¢„è§ˆ (å‰1000å­—ç¬¦): {result[:1000]}")
        
        # å¦‚æœç»“æœä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œè®°å½•è­¦å‘Š
        if not result or len(result.strip()) < 50:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ è¿”å›ç»“æœå¼‚å¸¸çŸ­æˆ–ä¸ºç©ºï¼")
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“ å®Œæ•´ç»“æœå†…å®¹: '{result}'")
        
        return result
    
    def _identify_stock_type(self, stock_code: str) -> str:
        """è¯†åˆ«è‚¡ç¥¨ç±»å‹"""
        stock_code = stock_code.upper().strip()
        
        # Aè‚¡åˆ¤æ–­
        if re.match(r'^(00|30|60|68)\d{4}$', stock_code):
            return "Aè‚¡"
        elif re.match(r'^(SZ|SH)\d{6}$', stock_code):
            return "Aè‚¡"
        
        # æ¸¯è‚¡åˆ¤æ–­
        elif re.match(r'^\d{4,5}\.HK$', stock_code):
            return "æ¸¯è‚¡"
        elif re.match(r'^\d{4,5}$', stock_code) and len(stock_code) <= 5:
            return "æ¸¯è‚¡"
        
        # ç¾è‚¡åˆ¤æ–­
        elif re.match(r'^[A-Z]{1,5}$', stock_code):
            return "ç¾è‚¡"
        elif '.' in stock_code and not stock_code.endswith('.HK'):
            return "ç¾è‚¡"
        
        # é»˜è®¤æŒ‰Aè‚¡å¤„ç†
        else:
            return "Aè‚¡"
    
    def _get_a_share_news(self, stock_code: str, max_news: int, model_info: str = "") -> str:
        """è·å–Aè‚¡æ–°é—»"""
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] è·å–Aè‚¡ {stock_code} æ–°é—»")
        
        # è·å–å½“å‰æ—¥æœŸ
        curr_date = datetime.now().strftime("%Y-%m-%d")
        
        # ä¼˜å…ˆçº§1: ä¸œæ–¹è´¢å¯Œå®æ—¶æ–°é—»
        try:
            if hasattr(self.toolkit, 'get_realtime_stock_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•ä¸œæ–¹è´¢å¯Œå®æ—¶æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_realtime_stock_news.invoke({"ticker": stock_code, "curr_date": curr_date})
                
                # ğŸ” è¯¦ç»†è®°å½•ä¸œæ–¹è´¢å¯Œè¿”å›çš„å†…å®¹
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“Š ä¸œæ–¹è´¢å¯Œè¿”å›å†…å®¹é•¿åº¦: {len(result) if result else 0} å­—ç¬¦")
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“‹ ä¸œæ–¹è´¢å¯Œè¿”å›å†…å®¹é¢„è§ˆ (å‰500å­—ç¬¦): {result[:500] if result else 'None'}")
                
                if result and len(result.strip()) > 100:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… ä¸œæ–¹è´¢å¯Œæ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "ä¸œæ–¹è´¢å¯Œå®æ—¶æ–°é—»", model_info)
                else:
                    logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ ä¸œæ–¹è´¢å¯Œæ–°é—»å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º")
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ä¸œæ–¹è´¢å¯Œæ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§2: Googleæ–°é—»ï¼ˆä¸­æ–‡æœç´¢ï¼‰
        try:
            if hasattr(self.toolkit, 'get_google_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•Googleæ–°é—»...")
                query = f"{stock_code} è‚¡ç¥¨ æ–°é—» è´¢æŠ¥ ä¸šç»©"
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_google_news.invoke({"query": query, "curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Googleæ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "Googleæ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] Googleæ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§3: OpenAIå…¨çƒæ–°é—»
        try:
            if hasattr(self.toolkit, 'get_global_news_openai'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•OpenAIå…¨çƒæ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_global_news_openai.invoke({"curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… OpenAIæ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "OpenAIå…¨çƒæ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] OpenAIæ–°é—»è·å–å¤±è´¥: {e}")
        
        return "âŒ æ— æ³•è·å–Aè‚¡æ–°é—»æ•°æ®ï¼Œæ‰€æœ‰æ–°é—»æºå‡ä¸å¯ç”¨"
    
    def _get_hk_share_news(self, stock_code: str, max_news: int, model_info: str = "") -> str:
        """è·å–æ¸¯è‚¡æ–°é—»"""
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] è·å–æ¸¯è‚¡ {stock_code} æ–°é—»")
        
        # è·å–å½“å‰æ—¥æœŸ
        curr_date = datetime.now().strftime("%Y-%m-%d")
        
        # ä¼˜å…ˆçº§1: Googleæ–°é—»ï¼ˆæ¸¯è‚¡æœç´¢ï¼‰
        try:
            if hasattr(self.toolkit, 'get_google_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•Googleæ¸¯è‚¡æ–°é—»...")
                query = f"{stock_code} æ¸¯è‚¡ é¦™æ¸¯è‚¡ç¥¨ æ–°é—»"
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_google_news.invoke({"query": query, "curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Googleæ¸¯è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "Googleæ¸¯è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] Googleæ¸¯è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§2: OpenAIå…¨çƒæ–°é—»
        try:
            if hasattr(self.toolkit, 'get_global_news_openai'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•OpenAIæ¸¯è‚¡æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_global_news_openai.invoke({"curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… OpenAIæ¸¯è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "OpenAIæ¸¯è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] OpenAIæ¸¯è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§3: å®æ—¶æ–°é—»ï¼ˆå¦‚æœæ”¯æŒæ¸¯è‚¡ï¼‰
        try:
            if hasattr(self.toolkit, 'get_realtime_stock_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•å®æ—¶æ¸¯è‚¡æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_realtime_stock_news.invoke({"ticker": stock_code, "curr_date": curr_date})
                if result and len(result.strip()) > 100:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… å®æ—¶æ¸¯è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "å®æ—¶æ¸¯è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å®æ—¶æ¸¯è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        return "âŒ æ— æ³•è·å–æ¸¯è‚¡æ–°é—»æ•°æ®ï¼Œæ‰€æœ‰æ–°é—»æºå‡ä¸å¯ç”¨"
    
    def _get_us_share_news(self, stock_code: str, max_news: int, model_info: str = "") -> str:
        """è·å–ç¾è‚¡æ–°é—»"""
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] è·å–ç¾è‚¡ {stock_code} æ–°é—»")
        
        # è·å–å½“å‰æ—¥æœŸ
        curr_date = datetime.now().strftime("%Y-%m-%d")
        
        # ä¼˜å…ˆçº§1: OpenAIå…¨çƒæ–°é—»
        try:
            if hasattr(self.toolkit, 'get_global_news_openai'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•OpenAIç¾è‚¡æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_global_news_openai.invoke({"curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… OpenAIç¾è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "OpenAIç¾è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] OpenAIç¾è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§2: Googleæ–°é—»ï¼ˆè‹±æ–‡æœç´¢ï¼‰
        try:
            if hasattr(self.toolkit, 'get_google_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•Googleç¾è‚¡æ–°é—»...")
                query = f"{stock_code} stock news earnings financial"
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_google_news.invoke({"query": query, "curr_date": curr_date})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Googleç¾è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "Googleç¾è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] Googleç¾è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        # ä¼˜å…ˆçº§3: FinnHubæ–°é—»ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            if hasattr(self.toolkit, 'get_finnhub_news'):
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] å°è¯•FinnHubç¾è‚¡æ–°é—»...")
                # ä½¿ç”¨LangChainå·¥å…·çš„æ­£ç¡®è°ƒç”¨æ–¹å¼ï¼š.invoke()æ–¹æ³•å’Œå­—å…¸å‚æ•°
                result = self.toolkit.get_finnhub_news.invoke({"symbol": stock_code, "max_results": min(max_news, 50)})
                if result and len(result.strip()) > 50:
                    logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… FinnHubç¾è‚¡æ–°é—»è·å–æˆåŠŸ: {len(result)} å­—ç¬¦")
                    return self._format_news_result(result, "FinnHubç¾è‚¡æ–°é—»", model_info)
        except Exception as e:
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] FinnHubç¾è‚¡æ–°é—»è·å–å¤±è´¥: {e}")
        
        return "âŒ æ— æ³•è·å–ç¾è‚¡æ–°é—»æ•°æ®ï¼Œæ‰€æœ‰æ–°é—»æºå‡ä¸å¯ç”¨"
    
    def _format_news_result(self, news_content: str, source: str, model_info: str = "") -> str:
        """æ ¼å¼åŒ–æ–°é—»ç»“æœ"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # ğŸ” æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼šæ‰“å°åŸå§‹æ–°é—»å†…å®¹
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“‹ åŸå§‹æ–°é—»å†…å®¹é¢„è§ˆ (å‰500å­—ç¬¦): {news_content[:500]}")
        logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ“Š åŸå§‹å†…å®¹é•¿åº¦: {len(news_content)} å­—ç¬¦")
        
        # æ£€æµ‹æ˜¯å¦ä¸ºGoogle/Geminiæ¨¡å‹
        is_google_model = any(keyword in model_info.lower() for keyword in ['google', 'gemini', 'gemma'])
        original_length = len(news_content)
        google_control_applied = False
        
        # ğŸ” æ·»åŠ Googleæ¨¡å‹æ£€æµ‹æ—¥å¿—
        if is_google_model:
            logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ¤– æ£€æµ‹åˆ°Googleæ¨¡å‹ï¼Œå¯ç”¨ç‰¹æ®Šå¤„ç†")
        
        # å¯¹Googleæ¨¡å‹è¿›è¡Œç‰¹æ®Šçš„é•¿åº¦æ§åˆ¶
        if is_google_model and len(news_content) > 5000:  # é™ä½é˜ˆå€¼åˆ°5000å­—ç¬¦
            logger.warning(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ”§ æ£€æµ‹åˆ°Googleæ¨¡å‹ï¼Œæ–°é—»å†…å®¹è¿‡é•¿({len(news_content)}å­—ç¬¦)ï¼Œè¿›è¡Œé•¿åº¦æ§åˆ¶...")
            
            # æ›´ä¸¥æ ¼çš„é•¿åº¦æ§åˆ¶ç­–ç•¥
            lines = news_content.split('\n')
            important_lines = []
            char_count = 0
            target_length = 3000  # ç›®æ ‡é•¿åº¦è®¾ä¸º3000å­—ç¬¦
            
            # ç¬¬ä¸€è½®ï¼šä¼˜å…ˆä¿ç•™åŒ…å«å…³é”®è¯çš„é‡è¦è¡Œ
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é‡è¦å…³é”®è¯
                important_keywords = ['è‚¡ç¥¨', 'å…¬å¸', 'è´¢æŠ¥', 'ä¸šç»©', 'æ¶¨è·Œ', 'ä»·æ ¼', 'å¸‚å€¼', 'è¥æ”¶', 'åˆ©æ¶¦', 
                                    'å¢é•¿', 'ä¸‹è·Œ', 'ä¸Šæ¶¨', 'ç›ˆåˆ©', 'äºæŸ', 'æŠ•èµ„', 'åˆ†æ', 'é¢„æœŸ', 'å…¬å‘Š']
                
                is_important = any(keyword in line for keyword in important_keywords)
                
                if is_important and char_count + len(line) < target_length:
                    important_lines.append(line)
                    char_count += len(line)
                elif not is_important and char_count + len(line) < target_length * 0.7:  # éé‡è¦å†…å®¹æ›´ä¸¥æ ¼é™åˆ¶
                    important_lines.append(line)
                    char_count += len(line)
                
                # å¦‚æœå·²è¾¾åˆ°ç›®æ ‡é•¿åº¦ï¼Œåœæ­¢æ·»åŠ 
                if char_count >= target_length:
                    break
            
            # å¦‚æœæå–çš„é‡è¦å†…å®¹ä»ç„¶è¿‡é•¿ï¼Œè¿›è¡Œè¿›ä¸€æ­¥æˆªæ–­
            if important_lines:
                processed_content = '\n'.join(important_lines)
                if len(processed_content) > target_length:
                    processed_content = processed_content[:target_length] + "...(å†…å®¹å·²æ™ºèƒ½æˆªæ–­)"
                
                news_content = processed_content
                google_control_applied = True
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âœ… Googleæ¨¡å‹æ™ºèƒ½é•¿åº¦æ§åˆ¶å®Œæˆï¼Œä»{original_length}å­—ç¬¦å‹ç¼©è‡³{len(news_content)}å­—ç¬¦")
            else:
                # å¦‚æœæ²¡æœ‰é‡è¦è¡Œï¼Œç›´æ¥æˆªæ–­åˆ°ç›®æ ‡é•¿åº¦
                news_content = news_content[:target_length] + "...(å†…å®¹å·²å¼ºåˆ¶æˆªæ–­)"
                google_control_applied = True
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] âš ï¸ Googleæ¨¡å‹å¼ºåˆ¶æˆªæ–­è‡³{target_length}å­—ç¬¦")
        
        # è®¡ç®—æœ€ç»ˆçš„æ ¼å¼åŒ–ç»“æœé•¿åº¦ï¼Œç¡®ä¿æ€»é•¿åº¦åˆç†
        base_format_length = 300  # æ ¼å¼åŒ–æ¨¡æ¿çš„å¤§æ¦‚é•¿åº¦
        if is_google_model and (len(news_content) + base_format_length) > 4000:
            # å¦‚æœåŠ ä¸Šæ ¼å¼åŒ–åä»ç„¶è¿‡é•¿ï¼Œè¿›ä¸€æ­¥å‹ç¼©æ–°é—»å†…å®¹
            max_content_length = 3500
            if len(news_content) > max_content_length:
                news_content = news_content[:max_content_length] + "...(å·²ä¼˜åŒ–é•¿åº¦)"
                google_control_applied = True
                logger.info(f"[ç»Ÿä¸€æ–°é—»å·¥å…·] ğŸ”§ Googleæ¨¡å‹æœ€ç»ˆé•¿åº¦ä¼˜åŒ–ï¼Œå†…å®¹é•¿åº¦: {len(news_content)}å­—ç¬¦")
        
        formatted_result = f"""
=== ğŸ“° æ–°é—»æ•°æ®æ¥æº: {source} ===
è·å–æ—¶é—´: {timestamp}
æ•°æ®é•¿åº¦: {len(news_content)} å­—ç¬¦
{f"æ¨¡å‹ç±»å‹: {model_info}" if model_info else ""}
{f"ğŸ”§ Googleæ¨¡å‹é•¿åº¦æ§åˆ¶å·²åº”ç”¨ (åŸé•¿åº¦: {original_length} å­—ç¬¦)" if google_control_applied else ""}

=== ğŸ“‹ æ–°é—»å†…å®¹ ===
{news_content}

=== âœ… æ•°æ®çŠ¶æ€ ===
çŠ¶æ€: æˆåŠŸè·å–
æ¥æº: {source}
æ—¶é—´æˆ³: {timestamp}
"""
        return formatted_result.strip()


def create_unified_news_tool(toolkit):
    """åˆ›å»ºç»Ÿä¸€æ–°é—»å·¥å…·å‡½æ•°"""
    analyzer = UnifiedNewsAnalyzer(toolkit)
    
    def get_stock_news_unified(stock_code: str, max_news: int = 100, model_info: str = ""):
        """
        ç»Ÿä¸€æ–°é—»è·å–å·¥å…·
        
        Args:
            stock_code (str): è‚¡ç¥¨ä»£ç  (æ”¯æŒAè‚¡å¦‚000001ã€æ¸¯è‚¡å¦‚0700.HKã€ç¾è‚¡å¦‚AAPL)
            max_news (int): æœ€å¤§æ–°é—»æ•°é‡ï¼Œé»˜è®¤100
            model_info (str): å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯ï¼Œç”¨äºç‰¹æ®Šå¤„ç†
        
        Returns:
            str: æ ¼å¼åŒ–çš„æ–°é—»å†…å®¹
        """
        if not stock_code:
            return "âŒ é”™è¯¯: æœªæä¾›è‚¡ç¥¨ä»£ç "
        
        return analyzer.get_stock_news_unified(stock_code, max_news, model_info)
    
    # è®¾ç½®å·¥å…·å±æ€§
    get_stock_news_unified.name = "get_stock_news_unified"
    get_stock_news_unified.description = """
ç»Ÿä¸€æ–°é—»è·å–å·¥å…· - æ ¹æ®è‚¡ç¥¨ä»£ç è‡ªåŠ¨è·å–ç›¸åº”å¸‚åœºçš„æ–°é—»

åŠŸèƒ½:
- è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹ï¼ˆAè‚¡/æ¸¯è‚¡/ç¾è‚¡ï¼‰
- æ ¹æ®è‚¡ç¥¨ç±»å‹é€‰æ‹©æœ€ä½³æ–°é—»æº
- Aè‚¡: ä¼˜å…ˆä¸œæ–¹è´¢å¯Œ -> Googleä¸­æ–‡ -> OpenAI
- æ¸¯è‚¡: ä¼˜å…ˆGoogle -> OpenAI -> å®æ—¶æ–°é—»
- ç¾è‚¡: ä¼˜å…ˆOpenAI -> Googleè‹±æ–‡ -> FinnHub
- è¿”å›æ ¼å¼åŒ–çš„æ–°é—»å†…å®¹
- æ”¯æŒGoogleæ¨¡å‹çš„ç‰¹æ®Šé•¿åº¦æ§åˆ¶
"""
    
    return get_stock_news_unified